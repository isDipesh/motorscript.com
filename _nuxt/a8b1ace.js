(window.webpackJsonp=window.webpackJsonp||[]).push([[4],{170:function(e,t,n){"use strict";var o={props:["title","published","updated","archived"],head:function(){return{title:this.title}}},r=n(8),component=Object(r.a)(o,(function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("div",[n("h1",{staticClass:"title",attrs:{itemprop:"name headline"}},[e._v(e._s(e.title))]),e._v(" "),n("div",{staticClass:"time"},[e._v("Published: "),n("time",{attrs:{itemprop:"datePublished"}},[e._v(e._s(e.published))])]),e._v(" "),e.updated?n("div",{staticClass:"time"},[e._v("Updated: "),n("time",{attrs:{itemprop:"dateModified"}},[e._v(e._s(e.updated))])]):e._e(),e._v(" "),e.archived?n("div",{staticClass:"block"},[e._v("Note: This is an archived post. Information may not be relevant now.")]):e._e()])}),[],!1,null,null,null);t.a=component.exports},176:function(e,t,n){"use strict";n.r(t);var o=n(170),r={mixins:[o.a],components:{BlogTitle:o.a}},l=n(8),component=Object(l.a)(r,(function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("article",{attrs:{itemprop:"blogPost",itemscope:"",itemtype:"https://schema.org/BlogPosting"}},[n("BlogTitle",{attrs:{title:"Automatically Run AWS Elastic Transcoder Jobs using Lambda Functions",published:"25 Jun 2020"}}),e._v(" "),n("div",{directives:[{name:"highlight",rawName:"v-highlight"}],staticClass:"content",attrs:{itemprop:"articleBody"}},[n("p",[e._v("\n        This tutorial will guide you through using S3 buckets to upload media\n        files and using lambda functions to automatically trigger a transcoding\n        job which saves output files to another bucket. This can be used to\n        create audio and video files of different quality and formats for\n        serving users.\n      ")]),e._v(" "),n("h2",[e._v("Create Amazon S3 Buckets")]),e._v(" "),e._m(0),e._v(" "),n("h2",[e._v("Create a Pipeline in AWS Elastic Transcoder")]),e._v(" "),e._m(1),e._v(" "),e._m(2),e._v(" "),e._m(3),e._v(" "),e._m(4),e._v(" "),n("p",[e._v("\n        Creating new jobs manually is time-consuming, hectic, and prone to\n        errors. We will automate this using Lambda functions and S3\n        notifications. As soon as we finish uploading a new file to the first S3\n        bucket, a notification will fire to trigger our Lambda function which\n        will then create an Elastic Transcoder Job to transcode the uploaded\n        file and save it to the second bucket, ready for consumption.\n      ")]),e._v(" "),n("h2",[e._v("Creating a role for Lambda execution")]),e._v(" "),e._m(5),e._v(" "),n("h2",[e._v("Creating the Lambda function")]),e._v(" "),e._m(6),e._v(" "),e._m(7),e._v(" "),e._m(8),e._v(" "),e._m(9),e._v(" "),n("h2",[e._v("Notifying Lambda for new uploads")]),e._v(" "),e._m(10)])],1)}),[function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("p",[e._v("\n        Create two S3 buckets â€“ one for uploading your media files, another one\n        to save, and distribute the transcoded files. The first bucket that\n        stores your uploads can be private whereas the second one needs to be\n        public if you want to use it to distribute the files. Select a region\n        closest to where most of your visitors/consumers are. You can create\n        buckets from\n        "),n("a",{attrs:{target:"_blank",rel:"noreferrer noopener",href:"https://s3.console.aws.amazon.com/s3/buckets/"}},[e._v("https://s3.console.aws.amazon.com/s3/buckets/")]),e._v(".\n      ")])},function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("p",[e._v("\n        You can access the Elastic Transcoder console from\n        "),n("a",{attrs:{target:"_blank",rel:"noreferrer noopener",href:"https://console.aws.amazon.com/elastictranscoder/"}},[e._v("https://console.aws.amazon.com/elastictranscoder/")]),e._v(". Selecting the same region for your transcoder and S3 buckets may save\n        you some costs. Now create a new Pipeline. Select the appropriate\n        buckets for input and output. To make the transcoded files publicly\n        accessible, provide "),n("span",{staticClass:"hl"},[e._v("Open/Download")]),e._v(" access to\n        "),n("span",{staticClass:"hl"},[e._v("All Users")]),e._v(" as shown in the screenshot below.\n      ")])},function(){var e=this.$createElement,t=this._self._c||e;return t("div",[t("img",{staticClass:"pt-1",attrs:{src:"/media/posts/amazon-s3-elastic-transcoder-pipeline-creation.png",alt:"AWS Elastic Transcoder Pipeline Creation",title:"AWS Elastic Transcoder Pipeline Creation"}})])},function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("p",[e._v("\n        Once the pipeline is created, view its details to note-down the\n        "),n("span",{staticClass:"hl"},[e._v("Pipeline ID")]),e._v(".\n      ")])},function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("p",[e._v("\n        A transcoding task is a "),n("span",{staticClass:"hl"},[e._v("Job")]),e._v(" in\n        "),n("span",{staticClass:"hl"},[e._v("Elastic Transcoder")]),e._v(". While the details for input\n        bucket, output bucket, and permissions are saved in\n        "),n("span",{staticClass:"hl"},[e._v("Pipeline")]),e._v(", other details for converting the file\n        is provided in the "),n("span",{staticClass:"hl"},[e._v("Job")]),e._v(". Each job needs a\n        pipeline.\n      ")])},function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("ul",[n("li",[e._v("\n          Visit\n          "),n("a",{attrs:{target:"_blank",rel:"noreferrer noopener",href:"https://console.aws.amazon.com/iam/home#/roles"}},[e._v("https://console.aws.amazon.com/iam/home#/roles")]),e._v("\n          and create a new role.\n        ")]),e._v(" "),n("li",[e._v("Choose "),n("span",{staticClass:"hl"},[e._v("Lambda")]),e._v(" as the common use case.")]),e._v(" "),n("li",[e._v("\n          Under permissions, attach the policies\n          "),n("span",{staticClass:"hl"},[e._v("AWSLambdaBasicExecutionRole")]),e._v(" and\n          "),n("span",{staticClass:"hl"},[e._v("AmazonElasticTranscoder_FullAccess")])]),e._v(" "),n("li",[e._v("Follow the next steps to complete creating the role.")])])},function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("div",[e._v("\n        Create a new Lambda function from\n        "),n("a",{attrs:{target:"_blank",rel:"noreferrer noopener",href:"https://console.aws.amazon.com/lambda/home"}},[e._v("https://console.aws.amazon.com/lambda/home.")])])},function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("div",[e._v("\n        Give it a name, choose "),n("span",{staticClass:"hl"},[e._v("Python 3.8")]),e._v(" as the\n        runtime, and select the role created in the last step under\n        "),n("span",{staticClass:"hl"},[e._v("Permissions")]),e._v(".\n      ")])},function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("pre",[n("code",{staticClass:"python language-python"},[e._v("import json\nimport os\nimport boto3\n\ndef lambda_handler(event, context):\n    pipeline_id = '[pipeline-id]'\n    hls_audio_160k_preset_id = '1351620000001-200060' # HLS Audio - 160k\n    segment_duration = '15'\n    transcoder = boto3.client('elastictranscoder')\n    out = []\n    for record in event['Records']:\n        bucket = record['s3']['bucket']['name']\n        key = record['s3']['object']['key']\n        # Strip the extension, Elastic Transcoder automatically adds one\n        key_sans_extension = os.path.splitext(key)[0]\n        outputs = [\n            {\n                'Key': key_sans_extension,\n                'PresetId': hls_audio_160k_preset_id,\n                'SegmentDuration': segment_duration,\n            }\n            ]\n        response = transcoder.create_job(PipelineId=pipeline_id,\n                                         Input={'Key': key},\n                                         Outputs=outputs,\n                                         )\n        print(response)\n        out.append(response)\n    return {\n        'statusCode': 200,\n        'body': out\n    }\n")])])},function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("p",[e._v("\n        The above code produces an "),n("span",{staticClass:"hl"},[e._v("HLS")]),e._v(" (m38u) audio\n        stream from the input file. You can use other presets as well. Multiple\n        output files can also be generated by providing different keys and\n        preset IDs in multiple dictionaries within the\n        "),n("span",{staticClass:"hl"},[e._v("output")]),e._v("\n        array.\n      ")])},function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("ul",[n("li",[e._v("\n          Visit\n          "),n("a",{attrs:{target:"_blank",rel:"noopener noreferrer",href:"https://s3.console.aws.amazon.com/s3/buckets/"}},[e._v("https://s3.console.aws.amazon.com/s3/buckets/")]),e._v("\n          and open the first bucket, the one where media is to be uploaded.\n        ")]),e._v(" "),n("li",[e._v("\n          Under "),n("span",{staticClass:"hl"},[e._v("Properties")]),e._v(", scroll down to\n          "),n("span",{staticClass:"hl"},[e._v("Event Notifications")]),e._v(".\n        ")]),e._v(" "),n("li",[e._v("Click "),n("span",{staticClass:"hl"},[e._v("Create event notificaton")]),e._v(".")]),e._v(" "),n("li",[e._v("\n          Give the notification a name, select\n          "),n("span",{staticClass:"hl"},[e._v("PUT")]),e._v(", and\n          "),n("span",{staticClass:"hl"},[e._v("Multipart upload completed")]),e._v(" events.\n          "),n("span",{staticClass:"hl"},[e._v("Multipart upload completed")]),e._v(" event is trigger\n          when large files are uploaded.\n        ")]),e._v(" "),n("li",[e._v("\n          If the lambda is to be triggered only for particular folders/prefixes\n          or file extension, specify using\n          "),n("span",{staticClass:"hl"},[e._v("Prefix")]),e._v(" and/or\n          "),n("span",{staticClass:"hl"},[e._v("Suffix")]),e._v(" fields.\n        ")]),e._v(" "),n("li",[e._v("\n          Select "),n("span",{staticClass:"hl"},[e._v("Lambda Function")]),e._v(" for notification\n          destination. Then, pick the lambda function created earlier and save\n          the form.\n        ")])])}],!1,null,null,null);t.default=component.exports}}]);